{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0b7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install duckdb==0.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b49b3-638a-4f2c-8247-e0a553d4c48c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea25c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94922463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandas==1.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ebfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4b6b5-4048-4a5d-897e-d8174c81faf5",
   "metadata": {},
   "source": [
    "** ** \n",
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de3d28-24fe-46d6-ba79-48838fdb9260",
   "metadata": {},
   "source": [
    "## **INGRESA NOMBRE DE JSON DE PARAMETROS** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe04096-19ba-4f18-9080-85cbebbee031",
   "metadata": {},
   "source": [
    "Respetar el formato para las carpetas **ejecuciones/periodo/cartera/nombres_json.json**\\\n",
    "Todo con minusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50729d0c-4253-4628-8e39-fcf534a8ae55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "#INGRESAR PARAMETROS#\n",
    "\n",
    "periodo = \"202404\"\n",
    "cartera = \"consumo\"\n",
    "version = \"FWL057_replica\"\n",
    "    \n",
    "##############################################################################################################\n",
    "import re\n",
    "year = \"2024\"\n",
    "import json\n",
    "\n",
    "CARPETA = f\"ejecuciones/{periodo}/{cartera}/{version}\"\n",
    "PARAMS_NAME = f\"params_{cartera}_{periodo}_v{version}.json\"\n",
    "\n",
    "PARAMS_PATH = f'{CARPETA}/{PARAMS_NAME}'\n",
    "\n",
    "with open(PARAMS_PATH, 'r') as file:\n",
    "    params_inputs = json.load(file)\n",
    "    \n",
    "print(\"Outputs:\", CARPETA)\n",
    "print(\"Nombre del json params:\", PARAMS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1605c5c-cb31-4802-a952-e3d2d847227a",
   "metadata": {
    "tags": []
   },
   "source": [
    "** ** \n",
    "** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4471f-3a0c-44d0-8e26-c008d784c986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "year = \"2024\"\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from libs.SageMakerFunx import *\n",
    "from libs.SageMakerTimeFunx import *\n",
    "from datetime import datetime\n",
    "from IPython.core.magic import register_line_magic\n",
    "\n",
    "@register_line_magic\n",
    "def print_execution_time(line):\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"Execution Time: {now}\")\n",
    "    \n",
    "PARAMS_PATH = f'{CARPETA}/{PARAMS_NAME}'\n",
    "\n",
    "with open(PARAMS_PATH, 'r') as file:\n",
    "    params_inputs = json.load(file)\n",
    "\n",
    "registro = params_inputs[\"params_variables\"]['registro']   # Nombre de la carpeta\n",
    "registro_ejecucion = params_inputs[\"params_variables\"]['registro_ejecucion'] # Usuario que ejecuta el notebook\n",
    "cartera = params_inputs[\"params_variables\"]['cartera']\n",
    "periodo = params_inputs[\"params_variables\"]['periodo']\n",
    "version = params_inputs[\"params_variables\"]['version']\n",
    "fwl_table_v = params_inputs[\"params_variables\"]['fwl_table_v']\n",
    "\n",
    "portfolio_filter = Portfolio_fwl_filter(cartera.lower())\n",
    "cartera, fwl_portfolio_name = portfolio_filter.get_actual_portfolio_name()\n",
    "\n",
    "json_file = f\"JSON_{cartera.upper()}_{periodo}_v{version}.json\"\n",
    "notebook_name = f\"HE_{cartera.upper()}_{periodo}_v{version}.ipynb\"\n",
    "\n",
    "# parametros del notebook\n",
    "nb_params = {'registro': registro.lower(),\n",
    "             'registro_ejec': registro_ejecucion.lower(),\n",
    "             'cartera': cartera.lower(),\n",
    "             'periodo': periodo.lower(),\n",
    "             'version': version.lower(),\n",
    "             'fwl_table_version':fwl_table_v,\n",
    "             'sufijo': params_inputs[\"sufijos_cartera\"][cartera],\n",
    "             'grupo_archivos': params_inputs[\"file_group\"][cartera].lower(),\n",
    "             'filtro_cartera_fwl': fwl_portfolio_name,\n",
    "             'json_file': json_file}\n",
    "\n",
    "vector_tables = list(value[1] for value in params_inputs[\"params_variables\"][\"tbl_names_per_portfolio\"][nb_params['grupo_archivos']].values())\n",
    "# imprimir parametros\n",
    "print(f\"PARÁMETROS DEL NOTEBOOK PARA {cartera.upper()}_{periodo}_v{version}\\n\")\n",
    "for nb_param, nb_key in nb_params.items():\n",
    "    print(f\"{nb_param}: {nb_key}\")\n",
    "print(\"--------------------------------------------------------------------\") \n",
    "print(\" \")   \n",
    "# 1: version nueva y 0 version actual (todo 1)\n",
    "print(f\"Status de tablas disponibles {nb_params['cartera'].upper()}\\n\")\n",
    "\n",
    "tbl_names_per_portfolio = reemplazar_params(params_inputs[\"params_variables\"][\"tbl_names_per_portfolio\"][nb_params['grupo_archivos']], nb_params)\n",
    "\n",
    "if fwl_table_v != \"0\":\n",
    "    tbl_names_per_portfolio['tbl_stress_pd'][1] = 1\n",
    "\n",
    "# total_tbl_names = tbl_names_per_portfolio[nb_params['grupo_archivos']]\n",
    "# new_tables = Read_preprocessing(vector_params, total_tbl_names, tablas_dict.copy(), nb_params).get_new_tables()\n",
    "    \n",
    "max_width = max(len(key) for key in tbl_names_per_portfolio.keys())\n",
    "max_value_width = max(len(value[0]) for value in tbl_names_per_portfolio.values())\n",
    "\n",
    "for key, value in tbl_names_per_portfolio.items():\n",
    "    # Ajustar el nombre de la tabla al ancho máximo con espacios\n",
    "    key_aligned = key.ljust(max_width)\n",
    "    arrow_padding = int(max_value_width/0.8) - len(value[0])\n",
    "    arrow_string = '-' * arrow_padding\n",
    "\n",
    "    # Crear la salida final con flechas\n",
    "    print(f\"{key_aligned}: {value[0]} {arrow_string}> status: {value[1]}\")\n",
    "print(\"--------------------------------------------------------------------\") \n",
    "print(\" \")\n",
    "\n",
    "number_of_thresholds = [number for number, list_portfolio in params_inputs[\"threshold_per_portfolio\"].items() \n",
    "                                if nb_params['cartera'] in list_portfolio][0]\n",
    "print(\"UMBRALES\")\n",
    "print(f\"Cartera: {nb_params['cartera'].upper()}\")\n",
    "print(f\"Numero de umbrales usados: {number_of_thresholds}\\n\")\n",
    "thresholds = list(params_inputs[\"params_variables\"][\"umbrales\"][str(number_of_thresholds)].values())\n",
    "for key, value in params_inputs[\"params_variables\"][\"umbrales\"][str(number_of_thresholds)].items():\n",
    "    print(f'{key}: ', value)\n",
    "print(\"--------------------------------------------------------------------\") \n",
    "print(\" \")\n",
    "\n",
    "n_peso_b = params_inputs[\"params_variables\"][\"pesos\"][\"n_peso_b\"]\n",
    "n_peso_o = params_inputs[\"params_variables\"][\"pesos\"][\"n_peso_o\"]\n",
    "n_peso_p = params_inputs[\"params_variables\"][\"pesos\"][\"n_peso_p\"]\n",
    "\n",
    "pesos = params_inputs[\"params_variables\"][\"pesos\"]\n",
    "\n",
    "print(\"PESOS\")\n",
    "print(f\"Cartera: {nb_params['cartera'].upper()}\\n\")\n",
    "for key, value in params_inputs[\"params_variables\"][\"pesos\"].items():\n",
    "    print(f'{key}: ', value)\n",
    "print(\"--------------------------------------------------------------------\") \n",
    "print(\" \")\n",
    "%print_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d9c63-e8b3-468e-9a13-3fe135caef12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bucket_name = params_inputs['rutas']['bucket']\n",
    "file_key = f\"{params_inputs['rutas']['carpet_prefix']}/Inputs_json/{nb_params['periodo']}/{nb_params['json_file']}\"\n",
    "\n",
    "log_ejec_global = []\n",
    "log_ejec_global_json = [] \n",
    "log_ejec_unico = []\n",
    "n_paso_ejecucion = 0\n",
    "\n",
    "s3_json = S3()\n",
    "# Carga JSON\n",
    "file_json = f\"s3://{bucket_name}/{file_key}\"\n",
    "print(\"file_json: \", file_json)\n",
    "\n",
    "reponse_json = s3_json.obtain_data(log_ejec_global_json, bucket_name, file_key)\n",
    "json_content = reponse_json[\"Body\"].read().decode(\"utf-8\") # **Ejecucion Parcial**\n",
    "\n",
    "data = json.loads(json_content)\n",
    "\n",
    "tablas_dict = {}\n",
    "general_params = {}\n",
    "escenarios = []\n",
    "\n",
    "s3 = S3()\n",
    "database_field = data[\"confPython\"]\n",
    "database_config = {\n",
    "    \"host\": database_field[\"host\"],\n",
    "    \"region\": database_field[\"region\"],\n",
    "    \"folderS3\": database_field[\"folderS3\"],\n",
    "    \"folderS3Destino\": database_field[\"folderS3Destino\"],\n",
    "    \"bd\": database_field[\"bd\"],\n",
    "    \"tablaAvance\": database_field[\"tablaAvance\"]\n",
    "}\n",
    "log_ejec_global.append(\"Inicializacion BBDD Athena\")\n",
    "pro_data = Process_data(database_config[\"bd\"], database_config[\"folderS3\"], database_config[\"folderS3Destino\"], database_config[\"region\"][\"id_region\"])\n",
    "\n",
    "# Datos de escenarios\n",
    "escenario_index = 1\n",
    "escenarios_field = data[\"escenarios\"]\n",
    "for escenario in escenarios_field:\n",
    "    formatted_escenario_dict = {\n",
    "        \"t_nombre_escenario\": escenario[\"nombre_escenario\"],\n",
    "        \"t_escenario\": escenario[\"nombre_escenario_motor\"],\n",
    "        \"n_cod_escenario\": escenario_index,\n",
    "        \"n_peso_escenario\": escenario[\"n_peso\"],\n",
    "        \"n_paso_ejecucion\": escenario[\"n_paso_ejecucion\"],\n",
    "        \"n_cod_ejecucion\": escenario[\"n_cod_ejecucion\"],\n",
    "        \"n_cod_escenario_version\": escenario[\"n_cod_escenario_version\"]\n",
    "    }\n",
    "    var_name = \"n_peso_\" + escenario[\"nombre_escenario\"][0].lower()\n",
    "    general_params[var_name] = escenario[\"n_peso\"]\n",
    "    escenarios.append(formatted_escenario_dict)\n",
    "    escenario_index += 1\n",
    "\n",
    "# Variables adicionales\n",
    "agrupacion_adicionales = data[\"vars_agrupacion_adicionales\"]\n",
    "staging_adicionales = data[\"vars_staging_adicionales\"]\n",
    "tabla_avance = ''\n",
    "n_region = ''\n",
    "\n",
    "general_params[\"agrupacion_adicionales\"] = agrupacion_adicionales\n",
    "general_params[\"staging_adicionales\"] = staging_adicionales\n",
    "\n",
    "for key in data:\n",
    "    if key not in [\"bloques\", \"escenarios\", \"confTeradata\", \"vars_agrupacion_adicionales\", \"adicionales\"]:\n",
    "        lower_key = key.lower()\n",
    "        general_params[lower_key] = data[key]\n",
    "\n",
    "# Poblado de bloques a partir de las Tablas de la BD\n",
    "bloques = data[\"bloques\"]\n",
    "tables_execution_start = time.time()\n",
    "for bloque in bloques:\n",
    "    if bloque[\"nombre_variable_motor\"] != \"Tbl_adicionales\":\n",
    "        keep_campos = []\n",
    "        nombre_campos = []\n",
    "        tipo_campos = {}\n",
    "\n",
    "        for campo in bloque[\"campos\"]:\n",
    "            nombre_campo = '' if campo[\"nombre_campo\"] is None else campo[\"nombre_campo\"]\n",
    "            nombre_variable = '' if campo[\"nombre_variable_motor\"] is None else campo[\"nombre_variable_motor\"].lower()\n",
    "            nombre_campo_format = nombre_campo\n",
    "            tipo = 'str'\n",
    "\n",
    "            if (campo[\"tipo_campo\"] == 1) or (campo[\"tipo_campo\"] == 4) and nombre_campo != '': \n",
    "                tipo = 'float64'\n",
    "\n",
    "            if nombre_campo != '':\n",
    "                keep_campos.append(nombre_campo_format)\n",
    "                nombre_campos.append(nombre_campo)\n",
    "                tipo_campos.update({nombre_campo:tipo})\n",
    "\n",
    "        filtro = bloque[\"filtro\"]\n",
    "        if filtro == '' or filtro is None:\n",
    "            filtro = None\n",
    "        else:\n",
    "            filtro = filtro.strip()\n",
    "\n",
    "        nombre_tabla = bloque[\"nombre_variable_motor\"].lower()#bloque[\"nombre_variable_motor\"].lower().replace(\"tbl\", \"tabla\")\n",
    "\n",
    "        #ejecucion de la query para obtener inputs\n",
    "        try:\n",
    "            query_id = pro_data.execute_query(log_ejec_global,bloque[\"nombre_tabla_fichero\"],crear_query_de_parametros(bloque[\"nombre_tabla_fichero\"], keep_campos, filtro, database_config[\"bd\"], bloque[\"listaCargas\"]))\n",
    "            log_ejec_global.append(query_id)\n",
    "            path_name = pro_data.bucket_query.split(\"s3://\")[1]\n",
    "            bucket_array = path_name.split(\"/\")\n",
    "            bucket_source = bucket_array[0]\n",
    "            path_key_source  = \"/\".join(bucket_array[1:]) + query_id + \".csv\"\n",
    "\n",
    "            response = s3.obtain_data(log_ejec_global,bucket_source,path_key_source)\n",
    "            tablas_dict[nombre_tabla] = pd.read_csv(io.BytesIO(response['Body'].read()), encoding='utf8',low_memory=False, dtype = tipo_campos)\n",
    "            log_ejec_global.append(f'fichero {nombre_tabla} cargado con {len(tablas_dict[nombre_tabla])} registros')\n",
    "            print(f'fichero {nombre_tabla} cargado con {len(tablas_dict[nombre_tabla])} registros')\n",
    "            if (len(tablas_dict[nombre_tabla]) == 0):\n",
    "                tablas_dict[nombre_tabla] = pd.DataFrame(columns=nombre_campos, index=[0])\n",
    "                tablas_dict[nombre_tabla] = tablas_dict[nombre_tabla].astype(dtype=tipo_campos)\n",
    "                tablas_dict[nombre_tabla].fillna(-999)\n",
    "                log_ejec_global.append(f'Atencion: el fichero {nombre_tabla} tiene 0 registros cargados, se podría generar un error en la ejecucion.')\n",
    "                print(f'Atencion: el fichero {nombre_tabla} tiene 0 registros cargados, se podría generar un error en la ejecucion.')\n",
    "        except:\n",
    "            t_error = traceback.format_exc().replace('\\\"','--')\n",
    "            log_ejec_global.append(f'Error lectura de inputs:\\r\\n{t_error}')\n",
    "            print(f'Error lectura de inputs:\\r\\n{t_error}')\n",
    "    else:\n",
    "        params = bloque[\"campos\"]\n",
    "        for param in params:\n",
    "            nombre_variable = '' if param[\"nombre_variable_motor\"] is None else param[\"nombre_variable_motor\"].lower()\n",
    "            valor_motor = param[\"valor_motor\"]\n",
    "            tipo = param[\"tipo_campo\"]\n",
    "\n",
    "            if tipo == 1:\n",
    "                valor_motor = int(valor_motor)\n",
    "            elif tipo == 4:\n",
    "                valor_motor = float(valor_motor)\n",
    "\n",
    "            general_params[nombre_variable] = valor_motor\n",
    "\n",
    "tables_execution_end = time.time()\n",
    "escenarios_executions_start = time.time()\n",
    "\n",
    "#tablas adicionales para staging y agrupacion de carteras\n",
    "agrupacion_adicionales = data[\"vars_agrupacion_adicionales\"]\n",
    "staging_adicionales = data[\"vars_staging_adicionales\"]\n",
    "\n",
    "final_agrupacion_adicionales = []\n",
    "final_staging_adicionales = []\n",
    "\n",
    "for object in agrupacion_adicionales:\n",
    "    new_object = object\n",
    "    for field in new_object:\n",
    "        if field not in [\"campo_llave_join\", \"campo_resultado_join\"]:\n",
    "            new_object[field] = new_object[field].lower()\n",
    "\n",
    "    new_object[\"tabla_join\"] = new_object[\"tabla_join\"]\n",
    "    final_agrupacion_adicionales.append(new_object)\n",
    "\n",
    "for object in staging_adicionales:\n",
    "    new_object = object\n",
    "    for field in new_object:\n",
    "        if field not in [\"campo_llave_join\", \"campo_resultado_join\"]:\n",
    "            new_object[field] = new_object[field].lower()\n",
    "\n",
    "    new_object[\"tabla_join\"] = new_object[\"tabla_join\"]\n",
    "    final_staging_adicionales.append(new_object)\n",
    "\n",
    "general_params[\"vars_agrupacion_adicionales\"] = final_agrupacion_adicionales\n",
    "general_params[\"vars_staging_adicionales\"] = final_staging_adicionales\n",
    "general_params[\"uma_avance_ejecucion\"] = tabla_avance\n",
    "general_params[\"region\"] = n_region\n",
    "\n",
    "n_paso_ejecucion_fin = 0;\n",
    "\n",
    "json_log_full = []\n",
    "\n",
    "general_params[\"n_fecha_referencia\"] = general_params[\"n_fechareferencia\"]\n",
    "general_params[\"n_cod_cartera_version\"] = general_params[\"n_cod_cartera_version\"]\n",
    "n_paso_ejecucion_fin = escenario[\"n_paso_ejecucion\"]\n",
    "tablas_params_manager = ParamsManager(tablas_dict)\n",
    "general_params_manager = ParamsManager(general_params)\n",
    "general_params[\"t_cartera\"] = general_params[\"t_cartera\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fdb68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tablas_dict_copy = tablas_dict.copy()\n",
    "general_params_copy = general_params.copy()\n",
    "vector_params = vector_tables.copy()\n",
    "\n",
    "#####################################################################################################\n",
    "## diccionario de tablas leidas desde athena\n",
    "\n",
    "total_tbl_names = {table: value[0] for table, value in tbl_names_per_portfolio.items()}\n",
    "new_tables = Read_preprocessing(vector_params, total_tbl_names, tablas_dict.copy(), nb_params).get_new_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446327f4-66e2-4987-b657-9a2b6516c571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mostrar nuevas tablas realizadas\n",
    "for tbl_name in new_tables:\n",
    "\n",
    "    if tbl_name in [\"tbl_bucket_pd\", \"tbl_bucket_limites\"]:\n",
    "        original_name = f\"Actual: {tbl_name}\"\n",
    "        new_name = f\"Nuevo: {tbl_name}\"\n",
    "        if tbl_name == 'tbl_bucket_pd':\n",
    "            display_dataframes_side_by_side(tablas_dict[tbl_name][tablas_dict[tbl_name][\"cartera\"]==cartera.upper()].head(10), \n",
    "                                            new_tables[tbl_name][new_tables[tbl_name][\"cartera\"]==cartera.upper()].head(10),\n",
    "                                            original_name, \n",
    "                                            new_name)\n",
    "\n",
    "        elif tbl_name == 'tbl_bucket_limites':\n",
    "            display_dataframes_side_by_side(tablas_dict[tbl_name][tablas_dict[tbl_name]['cartera'].str.contains(cartera.upper(), na=False)].sort_values(by=['bucket_score']).head(10), \n",
    "                                            new_tables[tbl_name][new_tables[tbl_name]['cartera'].str.contains(cartera.upper(), na=False)].sort_values(by=['bucket_score']).head(10),\n",
    "                                            original_name, \n",
    "                                            new_name)\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c73d0-29bb-46b8-bfb0-197f348d5657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mostrar nuevas tablas realizadas\n",
    "for tbl_name in new_tables:\n",
    "\n",
    "    if tbl_name in [\"tbl_matriz_anual\", \"tbl_stress_pd\"]:\n",
    "        \n",
    "        original_name = f\"Actual: {tbl_name}\"\n",
    "        new_name = f\"Nuevo: {tbl_name}\"\n",
    "        \n",
    "        if tbl_name == 'tbl_matriz_anual':\n",
    "            display_dataframes_side_by_side(tablas_dict[tbl_name][(tablas_dict[tbl_name]['N_bucket']==12.0)&(tablas_dict[tbl_name]['Periodo']==\"Originacion\")&(~tablas_dict[tbl_name]['N_estado_inicial'].isin([9.0, 10.0]))].sort_values(by=['N_estado_inicial']).head(10), \n",
    "                                            new_tables[tbl_name][(new_tables[tbl_name]['N_bucket']==12.0)&(new_tables[tbl_name]['Periodo']==\"Originacion\")&(~new_tables[tbl_name]['N_estado_inicial'].isin([9.0, 10.0]))].sort_values(by=['N_estado_inicial']).head(10),\n",
    "                                            original_name, \n",
    "                                            new_name)\n",
    "            \n",
    "        elif tbl_name == 'tbl_stress_pd':\n",
    "            display_dataframes_side_by_side(tablas_dict[tbl_name][(tablas_dict[tbl_name]['Mes']==12.0)].head(10), \n",
    "                                            new_tables[tbl_name][(new_tables[tbl_name]['Mes']==12.0)].head(10),\n",
    "                                            original_name, \n",
    "                                            new_name)\n",
    "    else:\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c081d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modified_string = Change_thresholds(nb_params['cartera'], general_params_copy[\"t_stg_filtro_prelacion\"], thresholds)\\\n",
    "                                    .update_thresholds()\n",
    "new_params = {}\n",
    "new_params = {\"t_stg_filtro_prelacion\": modified_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671c285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_params['n_peso_b'] = n_peso_b\n",
    "new_params['n_peso_o'] = n_peso_o\n",
    "new_params['n_peso_p'] = n_peso_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896f96f",
   "metadata": {},
   "source": [
    "**Cambiando tablas actuales por nuevas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a817f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for table_name in new_tables.keys():\n",
    "    print(f\"tablas_dict[{table_name}] <- new_tables[{table_name}]\")\n",
    "    tablas_dict_copy[table_name] = new_tables[table_name].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db3490",
   "metadata": {},
   "source": [
    "**Cambiando parametros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074af59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param_name in new_params.keys():\n",
    "    print(f\"general_params[{param_name}] <- new_params[{param_name}]\")\n",
    "    general_params_copy[param_name] = new_params[param_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59d3b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_tables_copy = tablas_dict_copy.copy()\n",
    "new_general_params_copy = general_params_copy.copy()\n",
    "\n",
    "tablas_params_manager = ParamsManager(tablas_dict_copy.copy())\n",
    "general_params_manager = ParamsManager(general_params_copy.copy())\n",
    "\n",
    "tablas = tablas_params_manager\n",
    "variables = general_params_manager\n",
    "\n",
    "T_cartera = variables.get_param(\"t_cartera\")\n",
    "T_cartera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a5025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_tbl_rcd_prep_base, temp_tbl_rcd_marca_s2 = preparacion_bases(log_ejec_unico, n_paso_ejecucion, tablas, variables)\n",
    "temp_tbl_asig_nivel_riesgo = asignacion_nivel_riesgo(log_ejec_unico, n_paso_ejecucion, tablas, variables, temp_tbl_rcd_prep_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebe452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "    temp_tbl_asig_pd = asignacion_pd(log_ejec_unico, n_paso_ejecucion, tablas, variables, temp_tbl_asig_nivel_riesgo)\n",
    "    \n",
    "if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "    temp_tbl_vida_media = asignacion_vida_media(log_ejec_unico, n_paso_ejecucion, tablas, variables, temp_tbl_asig_pd)\n",
    "    \n",
    "\n",
    "if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "    if T_cartera.upper() in ['HIPOTECAS', 'CONVENIOS']:\n",
    "        temp_tbl_pd_lifetime = asignacion_lifetime_HC(log_ejec_unico, n_paso_ejecucion, tablas, variables, temp_tbl_vida_media)\n",
    "    else:\n",
    "        temp_tbl_pd_lifetime = asignacion_lifetime(log_ejec_unico, n_paso_ejecucion, variables, temp_tbl_vida_media)\n",
    "        \n",
    "        \n",
    "if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "    if T_cartera.upper() in ['HIPOTECAS', 'CONVENIOS']:\n",
    "        temp_tbl_pd_lifetime = asignacion_lifetime_HC(log_ejec_unico, n_paso_ejecucion, tablas, variables, temp_tbl_vida_media)\n",
    "    else:\n",
    "        temp_tbl_pd_lifetime = asignacion_lifetime(log_ejec_unico, n_paso_ejecucion, variables, temp_tbl_vida_media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5592e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec85cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = current_time()\n",
    "\n",
    "output_provisiones=[]\n",
    "output_ead=[]\n",
    "output_parametros=[]\n",
    "output_tc_prodsubprod=[]\n",
    "output_stats=[]\n",
    "\n",
    "for k, escenario in enumerate(escenarios):\n",
    "    print(escenario[\"t_nombre_escenario\"])\n",
    "    log_ejec = []\n",
    "\n",
    "    if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "        temp_tbl_staging_stress, temp_tbl_stress_pd, N_stress_pd_fac_max, N_stress_pd_fac_Esc_actual_1 = stress_pd(log_ejec, n_paso_ejecucion, tablas, variables, escenario, temp_tbl_pd_lifetime)\n",
    "    else:\n",
    "        temp_tbl_pd_ref, temp_tbl_pd_ori, temp_tbl_pd_refinanciados, temp_tbl_pd_reprogramados, temp_tbl_pd_12_lt_missing, N_stress_pd_fac_Esc_actual_1 = MatricesPDStress(log_ejec, n_paso_ejecucion, tablas, variables, escenario)\n",
    "        temp_tbl_staging_stress = StagingAsignacionPdTC(log_ejec, n_paso_ejecucion, tablas, variables, escenario, temp_tbl_asig_nivel_riesgo, temp_tbl_pd_ref, temp_tbl_pd_ori, temp_tbl_pd_refinanciados, temp_tbl_pd_reprogramados, temp_tbl_pd_12_lt_missing)\n",
    "    temp_tbl_staging = asignacion_stage(log_ejec, n_paso_ejecucion, variables, temp_tbl_staging_stress)\n",
    "    if T_cartera.upper() in ['TARJETAS', 'RAPPI']:\n",
    "        temp_tbl_staging = AsignacionCcfEad(log_ejec, n_paso_ejecucion, tablas, variables, escenario, temp_tbl_staging)\n",
    "        temp_ecl_stress_pd_marginal = None\n",
    "        temp_tbl_ead_consolidada = None\n",
    "    temp_tbl_staging_prov = asignacion_lgd_y_agregacion(log_ejec, n_paso_ejecucion, tablas, variables, escenario, temp_tbl_staging)\n",
    "    if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "        if (k == 0) | (escenario['t_escenario'] == \"N\"):\n",
    "            # EAD\n",
    "            temp_tbl_cron_cartera_s1 = cron_cartera(log_ejec, n_paso_ejecucion, tablas, variables)\n",
    "            temp_tbl_ead_saldo_base_ref = saldos_mes_referencia(log_ejec, n_paso_ejecucion, tablas, variables, temp_tbl_staging_prov, temp_tbl_cron_cartera_s1)\n",
    "            temp_tbl_ead_cuotas_futuras = saldos_cuotas_futuras(log_ejec, n_paso_ejecucion, tablas, variables, temp_tbl_ead_saldo_base_ref, temp_tbl_cron_cartera_s1)\n",
    "            temp_tbl_ead_consolidada = saldos_proyectados(log_ejec, n_paso_ejecucion, tablas, variables, temp_tbl_ead_saldo_base_ref, temp_tbl_ead_cuotas_futuras)\n",
    "            # ECL\n",
    "            temp_tbl_ecl_saldos_vp = saldo_anual_valorpresente(log_ejec, n_paso_ejecucion, variables, temp_tbl_ead_consolidada)\n",
    "            temp_tbl_ecl_pd_lgd_ead = agregacion_pd_lgd_ead(log_ejec, n_paso_ejecucion, variables, temp_tbl_staging_prov, temp_tbl_ecl_saldos_vp)\n",
    "            temp_tbl_pd_marg = asignacion_pd_marginal(log_ejec, n_paso_ejecucion, tablas, variables, temp_tbl_ecl_pd_lgd_ead)\n",
    "        temp_ecl_stress_pd_marginal = stress_pd_marginal(log_ejec, n_paso_ejecucion, variables, N_stress_pd_fac_max, temp_tbl_stress_pd, temp_tbl_pd_marg)##\n",
    "    temp_tbl_ecl_calculo_prov = calculo_provisiones(log_ejec, n_paso_ejecucion, tablas, variables, temp_ecl_stress_pd_marginal, temp_tbl_staging_prov)\n",
    "    tabla_agregada_results = tabla_agregada(log_ejec, n_paso_ejecucion, tablas, variables, escenario, N_stress_pd_fac_Esc_actual_1, temp_tbl_ecl_calculo_prov, temp_tbl_rcd_prep_base, temp_tbl_staging_stress, temp_tbl_ead_consolidada, temp_tbl_rcd_marca_s2)\n",
    "    \n",
    "    output_provisiones.append(tabla_agregada_results[\"pe_total_escenario\"])\n",
    "    output_ead.append(tabla_agregada_results[\"ead_total_escenario\"])\n",
    "    output_parametros.append(tabla_agregada_results[\"pe_parametros_escenario\"])\n",
    "    output_tc_prodsubprod.append(tabla_agregada_results[\"prod_subprod_escenario\"])\n",
    "    output_stats.append(tabla_agregada_results[\"tabla_stats\"])\n",
    "    \n",
    "end_time = current_time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55aa45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_provisiones_full = pd.concat(output_provisiones, ignore_index = True)\n",
    "output_ead_full = pd.concat(output_ead, ignore_index = True)\n",
    "output_parametros_full = pd.concat(output_parametros, ignore_index = True)\n",
    "output_tc_prodsubprod_full = pd.concat(output_tc_prodsubprod, ignore_index = True)\n",
    "output_stats_full = pd.concat(output_stats, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67646a",
   "metadata": {},
   "source": [
    "## Exportar a S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8935ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = \"interbank-datalake-us-east-1-428938305480-discovery\"\n",
    "file_key = f\"ifrs/discovery/discovery_riesgos_calibracion/Calibracion-{year}/Impactos/{nb_params['registro']}/resultados_he/{nb_params['periodo']}/carteras/{nb_params['cartera']}/output_v{nb_params['version']}\"\n",
    "print(file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f8173",
   "metadata": {},
   "source": [
    "**tablas de salida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1478bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_out = f\"s3://{bucket_name}/{file_key}\"\n",
    "\n",
    "dict_exportacion = {\"HOA_OUTPUTPROVISIONESCRED\": output_provisiones_full,\n",
    "                   \"HOA_OUTPUTEADCONSOLIDADO\": output_ead_full,\n",
    "                   \"HOA_OUTPUTMAESTROPARAMETROS\": output_parametros_full,\n",
    "                   \"HOA_OUTPUTPRODSUBPRODTC\": output_tc_prodsubprod_full,\n",
    "                   \"HOA_OUTPUTSTATS\": output_stats_full}\n",
    "\n",
    "for name, df in dict_exportacion.items():\n",
    "    df.to_parquet(f\"{path_out}/{name}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e2c41",
   "metadata": {},
   "source": [
    "**tablas de entrada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988413b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name in tablas_dict:\n",
    "    tablas.get_param(name).to_parquet(f\"{path_out}/{name}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72622eb",
   "metadata": {},
   "source": [
    "**tablas intermedias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00fb36-0d59-4be8-96b3-09dcf4272393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if T_cartera.upper() not in ['TARJETAS', 'RAPPI']:\n",
    "    dict_exportacion_int = {\"temp_tbl_rcd_prep_base\": temp_tbl_rcd_prep_base,\n",
    "                           \"temp_tbl_rcd_marca_s2\": temp_tbl_rcd_marca_s2,\n",
    "                           \"temp_tbl_asig_nivel_riesgo\": temp_tbl_asig_nivel_riesgo,\n",
    "                           \"temp_tbl_vida_media\": temp_tbl_vida_media,\n",
    "                           \"temp_tbl_pd_lifetime\": temp_tbl_pd_lifetime}\n",
    "else:\n",
    "    dict_exportacion_int = {\"temp_tbl_rcd_prep_base\": temp_tbl_rcd_prep_base,\n",
    "                           \"temp_tbl_rcd_marca_s2\": temp_tbl_rcd_marca_s2,\n",
    "                           \"temp_tbl_asig_nivel_riesgo\": temp_tbl_asig_nivel_riesgo}\n",
    "\n",
    "for name, df in dict_exportacion_int.items():\n",
    "    df.to_parquet(f\"{path_out}/{name}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaeac62-1d26-4a66-b37f-4c0b2398c22d",
   "metadata": {},
   "source": [
    "## VERSIONAMIETNO DE LOS PARAMETROS APLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01980faf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_params_version = {key: value for key, value in nb_params.items() if key in ['registro_ejec', 'cartera', 'periodo', 'version']}\n",
    "nb_params_version['tablas actualizadas'] = ' - '.join(list(new_tables.keys()))\n",
    "if nb_params['cartera'] not in ['corporativa', 'institucional', 'inmobiliarias']:\n",
    "    if nb_params['cartera'] == 'hipotecas':\n",
    "        string_mivienda = f\"MiVivienda: {{{' - '.join(map(str,(thresholds[:2])))}}}\"\n",
    "        string_tradicional = f\"Tradicional: {{{' - '.join(map(str,(thresholds[2:])))}}}\"\n",
    "        nb_params_version['umbrales actualizados'] = f\"{string_mivienda}; {string_tradicional}\"\n",
    "    else:\n",
    "        nb_params_version['umbrales actualizados'] = ' - '.join(map(str,(thresholds)))\n",
    "else:\n",
    "    nb_params_version['umbrales actualizados'] = 'cartera sin umbrales'\n",
    "\n",
    "# output path\n",
    "bucket_name = \"interbank-datalake-us-east-1-428938305480-discovery/\"\n",
    "file_key_ouput = f\"ifrs/discovery/discovery_riesgos_calibracion/Calibracion-{year}/Impactos/{nb_params['registro']}/resultados_he/{nb_params['periodo']}/carteras/{nb_params['cartera']}/output_v{nb_params['version']}\"\n",
    "ruta_output = \"s3://\" + bucket_name + file_key\n",
    "nb_params_version['ruta_output'] = ruta_output\n",
    "\n",
    "# Macroeconomic scenarios\n",
    "parametros_fwl = {\n",
    "                'base':new_params['n_peso_b'],\n",
    "                'optimista':new_params['n_peso_o'],\n",
    "                'pesimista':new_params['n_peso_p']\n",
    "}\n",
    "\n",
    "nb_params_version['pesos fwl'] = parametros_fwl\n",
    "\n",
    "# Inputs tables names\n",
    "tablas_inputs = {}\n",
    "for key, value in total_tbl_names.items():\n",
    "    tablas_inputs[key] = value\n",
    "nb_params_version['Tablas inputs'] = tablas_inputs\n",
    "\n",
    "# Inputs tables 1/0 version\n",
    "inputs_tablas_dummy = dict(zip(list(total_tbl_names.keys()),vector_params)) \n",
    "nb_params_version['Actualizacion de tablas'] = inputs_tablas_dummy\n",
    "\n",
    "# Json input\n",
    "json_file\n",
    "nb_params_version['JSON'] = json_file\n",
    "\n",
    "# Time execution\n",
    "spent_time = end_time - start_time\n",
    "nb_params_version['Fecha, hora y tiempo de ejecucion'] = f\"{format_time(start_time)} ::: [{execution_time_report(spent_time)}]\"\n",
    "\n",
    "nb_params_version = pd.DataFrame([nb_params_version])\n",
    "nb_params_version = pd.DataFrame(nb_params_version.set_index(['cartera', 'periodo', 'version']).stack(), \n",
    "                                 columns = [''])\n",
    "nb_params_version.index.names = ['cartera', 'periodo', 'version', 'parametro']\n",
    "nb_params_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122eef2-3e3e-4e3e-b15c-579413a56d69",
   "metadata": {},
   "source": [
    "## CALCULO DE PROVISIONES Y RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0be08d-7da0-4fe5-ab95-5cd1850e0288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.10f}'.format)\n",
    "np.set_printoptions(suppress=True)\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'interbank-datalake-us-east-1-428938305480-discovery'\n",
    "prefix = f'ifrs/discovery/discovery_riesgos_calibracion/Calibracion-{year}/Impactos/Notebooks/{periodo}/{cartera.upper()}/output_v{version}'\n",
    "notebook = f'{prefix}/{notebook_name}'\n",
    "json = f'{prefix}/{PARAMS_NAME}'\n",
    "\n",
    "NOTEBOOK_PATH = 'Herramienta_estrategica.ipynb'\n",
    "CSV_OUTPUT_PATH = f\"{PARAMS_PATH.split('/params')[0]}/output_{cartera}_{periodo}_v{version}.csv\"\n",
    "nb_params_version.to_csv(CSV_OUTPUT_PATH)\n",
    "\n",
    "## Provisiones\n",
    "\n",
    "path_impactos = f\"s3://{bucket_name}/{file_key}/HOA_OUTPUTPROVISIONESCRED.parquet\"\n",
    "impactos = pd.read_parquet(path_impactos)\n",
    "\n",
    "ESC_BAS = n_peso_b\n",
    "ESC_OPT = n_peso_o\n",
    "ESC_PES = n_peso_p\n",
    "\n",
    "path_with_name = f's3://{bucket_name}/{prefix}/impactos_he_{cartera}_{periodo}_v{version}.csv'\n",
    "\n",
    "provisiones = calculo_provisiones_glue(impactos, cartera, ESC_BAS , ESC_OPT, ESC_PES, path_with_name)\n",
    "\n",
    "provisiones_sm = f\"{PARAMS_PATH.split('/params')[0]}/impactos_he_{cartera}_{periodo}_v{version}.csv\"\n",
    "provisiones.to_csv(provisiones_sm, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223583b-a89b-4dd6-ba1a-1fb412ed7cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225356e-2c53-41f5-b67b-291b4365f82a",
   "metadata": {},
   "source": [
    "## SUBIDA DE RESULTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcbb77-8dd2-4412-8588-31aad2949ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sube el archivo al bucket\n",
    "s3.upload_file(NOTEBOOK_PATH, bucket_name, notebook)\n",
    "s3.upload_file(PARAMS_PATH, bucket_name, json)\n",
    "s3.upload_file(CSV_OUTPUT_PATH, bucket_name,f'{prefix}/output_{cartera}_{periodo}_v{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee14d0b-9167-433c-9680-41f9333d39f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a39c25-fe73-483d-a299-074a35f8b93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dff83f-3d7f-43f5-a28d-4d534d5cb085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f5965-3906-4723-a57f-87f98f592fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
